{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKD6wTKQnpByQbJHGIKIXn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaheepChaudhary/GANs_mnist/blob/main/GANs_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEkdz4JuXzvy"
      },
      "source": [
        "#importing the necessary packages\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.datasets import mnist \n",
        "import imageio\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.layers import Dense,Conv2DTranspose,Conv2D,Dropout,Flatten,MaxPool2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w82vs-ntOVET"
      },
      "source": [
        "#preprocessing of dataset(normalization and shuffling of images)\n",
        "dataset = mnist.load_data(path=\"mnist.npz\")\n",
        "x_train,y_train,x_test,y_test = dataset[0][0],dataset[0][1],dataset[1][0],dataset[1][1]\n",
        "x_train = x_train/255.0;x_test = x_test/255.0\n",
        "x_train,y_train = shuffle(x_train,y_train)\n",
        "x_test,y_test = shuffle(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aztTGiy9OvDp"
      },
      "source": [
        "#generator model\n",
        "def generator(noise):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(noise))\n",
        "  model.add(tf.keras.layers.Reshape(None,28,28,1))\n",
        "  model.add(Conv2DTranspose(256,activations = 'relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2DTranspose(128,activations = 'relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2DTranspose(64,activations = 'relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPw9BiyjO4RW"
      },
      "source": [
        "#discriminator model\n",
        "def discriminator(image):\n",
        "  model = Sequential()  \n",
        "  model.add(Conv2D(64,kernel = (3,3),activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(128,kernel = (3,3),activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(256,kernel = (3,3),activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(200,activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(100,activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(50,activation='relu'))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7HRC0IyO794"
      },
      "source": [
        "#loss\n",
        "#loss = tk.losses.binary_crossentropy(from_logits = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJWI2sE1O9nw"
      },
      "source": [
        "#optimizers\n",
        "gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "dis_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPSlOhiLO-zB"
      },
      "source": [
        "#generative_loss\n",
        "def gen_loss(fake):\n",
        "  return tk.losses.binary_crossentropy(tf.zeros_like(fake),fake,from_logits = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqPfKuQiPCbC"
      },
      "source": [
        "#discriminator_loss\n",
        "def dis_loss(fake,original):\n",
        "  real_loss = tk.losses.binary_crossentropy(tf.ones_like(original),original,from_logits = True)\n",
        "  fake_loss = tk.losses.binary_crossentropy(tf.zeros_like(fake),fake,from_logits = True)  \n",
        "  total_loss= real_loss + fake_loss\n",
        "  return total_loss  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpVvDkxKPH5N"
      },
      "source": [
        "#training_Step\n",
        "no_of_examples = 16\n",
        "noise_dim = 100\n",
        "noise = tf.random.normal(no_of_examples,noise_dim)\n",
        "\n",
        "def train_step(images,batch_size):\n",
        "  t = batch_size\n",
        "  noise = tf.random.normal(batch_size,noise_dim)\n",
        "  \n",
        "  with tf.GradientTape as gen_tape, tf.GradientTape as dis_tape:\n",
        "    gen_images = generator(noise,trainable = True)\n",
        "    original = discriminator(images,trainable = True) \n",
        "    fake = discriminator(gen_images,trainable = True)\n",
        "    generator_loss,discriminator_loss = gen_loss(fake),dis_loss(fake,original)\n",
        "    gen_gradient,dis_gradient = gen_tape.gradient(generator_loss,generator.trainable_variables),gen_tape.gradient(discriminator_loss,discriminator.trainable_variables)\n",
        "\n",
        "  gen_optimizer(gen_gradient,generator.trainable_variables)\n",
        "  dis_optimizer(dis_gradient,discriminator.trainable_variables)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65qlLj_JPNf4"
      },
      "source": [
        "#training_function\n",
        "epochs = 50\n",
        "batch_size = 256\n",
        "def train(dataset):\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKWoR_LTPQ2a"
      },
      "source": [
        "#plotting and saving image function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VszWgn0lSXUS",
        "outputId": "51e166df-1c01-4ec9-c6d8-62dce56b0a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#training occurs\n",
        "def add(x,y):\n",
        "  print(x+y)\n",
        "x = [1,2,3,4,4]\n",
        "y = [4,1,1,1,1]\n",
        "add(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 4, 4, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2adoCejtku"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}